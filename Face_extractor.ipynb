{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "from deepface import DeepFace\n",
    "\n",
    "# Path to your folder with frames\n",
    "frames_folder = \"./happy\"\n",
    "\n",
    "# Store results in a dictionary\n",
    "emotions_count = {}\n",
    "\n",
    "# Loop through each frame in the folder\n",
    "for frame_file in sorted(os.listdir(frames_folder)):\n",
    "    if frame_file.endswith(\".png\"):  # Adjust if your frames are in JPEG or another format\n",
    "        # Load the frame\n",
    "        frame_path = os.path.join(frames_folder, frame_file)\n",
    "        frame = cv2.imread(frame_path)\n",
    "        \n",
    "        # Check if the frame was loaded successfully\n",
    "        if frame is None:\n",
    "            print(f\"Failed to load frame: {frame_file}\")\n",
    "            continue\n",
    "        \n",
    "        # Apply contrast enhancement and sharpening\n",
    "        alpha = 1.5  # Contrast control\n",
    "        beta = 20    # Brightness control\n",
    "        enhanced_frame = cv2.convertScaleAbs(frame, alpha=alpha, beta=beta)\n",
    "        \n",
    "        # Sharpening filter\n",
    "        kernel = np.array([[0, -1, 0], [-1, 5, -1], [0, -1, 0]])\n",
    "        sharpened_frame = cv2.filter2D(enhanced_frame, -1, kernel)\n",
    "        \n",
    "        # Resize the frame for DeepFace\n",
    "        resized_frame = cv2.resize(sharpened_frame, (224, 224))\n",
    "        \n",
    "        try:\n",
    "            # Detect emotions with DeepFace\n",
    "            analysis = DeepFace.analyze(resized_frame, actions=['emotion'], enforce_detection=False)\n",
    "            \n",
    "            # Check if analysis is a list and get the first element if it is\n",
    "            if isinstance(analysis, list):\n",
    "                analysis = analysis[0]\n",
    "            \n",
    "            # Extract dominant emotion\n",
    "            emotion = analysis.get('dominant_emotion')\n",
    "            if emotion:\n",
    "                print(f\"Detected {emotion} in frame: {frame_file}\")\n",
    "                \n",
    "                # Update emotion count\n",
    "                if emotion in emotions_count:\n",
    "                    emotions_count[emotion] += 1\n",
    "                else:\n",
    "                    emotions_count[emotion] = 1\n",
    "            else:\n",
    "                print(f\"No emotion detected in frame: {frame_file}\")\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing frame {frame_file}: {e}\")\n",
    "\n",
    "# Determine the most common emotion, if any emotions were detected\n",
    "if emotions_count:\n",
    "    main_emotion = max(emotions_count, key=emotions_count.get)\n",
    "    print(f\"The main emotion detected in the video is: {main_emotion}\")\n",
    "else:\n",
    "    print(\"No emotions were detected across all frames.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
