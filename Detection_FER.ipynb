{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "from fer import FER\n",
    "\n",
    "# Path to your folder with frames\n",
    "frames_folder = \"./fear\"\n",
    "\n",
    "# Load FER detector\n",
    "detector = FER()\n",
    "\n",
    "# Store results in a dictionary\n",
    "emotions_count = {}\n",
    "\n",
    "# Loop through each frame in the folder\n",
    "for frame_file in sorted(os.listdir(frames_folder)):\n",
    "    if frame_file.endswith(\".png\"):  # Adjust if your frames are in JPEG or another format\n",
    "        # Load the frame\n",
    "        frame_path = os.path.join(frames_folder, frame_file)\n",
    "        frame = cv2.imread(frame_path)\n",
    "        \n",
    "        # Check if the frame was loaded successfully\n",
    "        if frame is None:\n",
    "            print(f\"Failed to load frame: {frame_file}\")\n",
    "            continue\n",
    "        \n",
    "        # Apply contrast enhancement and sharpening\n",
    "        alpha = 1.5  # Contrast control\n",
    "        beta = 20    # Brightness control\n",
    "        enhanced_frame = cv2.convertScaleAbs(frame, alpha=alpha, beta=beta)\n",
    "        \n",
    "        # Sharpening filter\n",
    "        kernel = np.array([[0, -1, 0], [-1, 5, -1], [0, -1, 0]])\n",
    "        sharpened_frame = cv2.filter2D(enhanced_frame, -1, kernel)\n",
    "        \n",
    "        # Resize the frame\n",
    "        resized_frame = cv2.resize(sharpened_frame, (224, 224))\n",
    "        \n",
    "        try:\n",
    "            # Detect emotions\n",
    "            emotions = detector.detect_emotions(resized_frame)\n",
    "            if emotions:\n",
    "                print(f\"Detected emotions in frame: {frame_file}\")\n",
    "                emotion = max(emotions[0][\"emotions\"], key=emotions[0][\"emotions\"].get)\n",
    "                print(emotion)\n",
    "                if emotion in emotions_count:\n",
    "                    emotions_count[emotion] += 1\n",
    "                else:\n",
    "                    emotions_count[emotion] = 1\n",
    "            else:\n",
    "                print(f\"No face detected in frame: {frame_file}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing frame {frame_file}: {e}\")\n",
    "            \n",
    "# Determine the most common emotion, if any emotions were detected\n",
    "if emotions_count:\n",
    "    main_emotion = max(emotions_count, key=emotions_count.get)\n",
    "    print(f\"The main emotion detected in the video is: {main_emotion}\")\n",
    "else:\n",
    "    print(\"No emotions were detected across all frames.\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
